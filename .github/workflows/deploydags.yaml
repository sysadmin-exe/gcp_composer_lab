name: Deploy DAGs to Composer

on: [push]

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@master

    # Setup gcloud CLI
    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@master
      with:
        service_account_email: ${{ secrets.GCP_EMAIL }}
        service_account_key:  ${{ secrets.GCP_CREDENTIALS }}
        export_default_credentials: true
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    - name: Use gcloud CLI
      run: gcloud info

    # Upload files to data directory GCS so that a test can be run on the DAGs
    # - id: upload-dags-to-gcs-dag-dir
    #   name: upload DAGs to GCS DAG dir for Airflow
    #   uses: google-github-actions/upload-cloud-storage@main
    #   with:
    #     path: ./dags/
    #     destination: europe-west1-firstcomposer-de8e6ba3-bucket/dags/
    #     glob: '*.py'

    - id: upload-dags-to-gcs-dag-dir
      name: upload DAGs to GCS DAG dir for Airflow
      run: |
        gsutil cp ./dags/*.py gs://europe-west1-firstcomposer-de8e6ba3-bucket/dag/


    # Example of using the output
    # - id: uploaded-files
    #   name: output the file name uploaded
    #   uses: google-github-actions/upload-cloud-storage@main
    #   env:
    #     file: ${{steps.upload-file.outputs.uploaded}}%